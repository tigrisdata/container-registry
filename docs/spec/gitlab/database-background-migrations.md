# Batched Background Migrations (BBMs)

## Introduction

Batched background migrations provide a mechanism for performing large-scale database migrations efficiently and safely, without compromising system performance or availability. This approach divides extensive migration tasks into smaller, manageable chunks that can be processed incrementally in the background.

The Registry implements a background migration system supporting both asynchronous and synchronous execution modes. In the asynchronous mode, migrations run in the background during normal registry operation, using a worker that periodically checks for and processes pending jobs in batches, minimizing impact on system performance. The synchronous mode enables on-demand execution of background migrations, typically during maintenance operations, offering more immediate processing of migration tasks when necessary.

Key features of the Registry's background migration system include:

1. **Job batching**: Divides migration tasks into smaller, manageable chunks for efficient processing
1. **Flexible execution modes**: Supports both asynchronous (background) and synchronous (on-demand) migration execution
1. **Error handling**: Implements mechanisms to detect, log, and manage issues during migration processes
1. **Comprehensive monitoring**: Provides tools to track migration status
1. **Migration dependencies**: Allows for enforced migrations to ensure critical data changes are completed before dependent operations
1. **Distributed execution**: Uses a locking mechanism to prevent conflicts in distributed environments
1. **Persistence**: Stores migration metadata and job execution details in dedicated database tables for tracking and management

The system is underpinned by two key database tables: the `batched_background_migrations` table for tracking migration metadata, and the `batched_background_migration_jobs` table for recording execution details of individual migration jobs. A distributed lock mechanism ensures that only one instance processes a given migration at a time, preventing conflicts in distributed environments. This architecture enables the Registry to seamlessly execute complex database operations while maintaining data consistency and enhancing overall system reliability.

## Structure

The Registry's implementation of batched background migrations draws inspiration from the GitLab Rails background migration system, with some minor differences tailored to the Registry's specific needs. While the core concept remains similar, the Registry's implementation includes additional/modified fields. For more details on the Rails inspiration, you can refer to [the GitLab database structure](https://gitlab.com/gitlab-org/gitlab/-/blob/master/db/structure.sql?ref_type=heads#L7059). The Registry's batched background migration tables are structured as follows:

### Database Schema

#### Migrations

```sql
CREATE TABLE batched_background_migrations (
    id bigint NOT NULL GENERATED BY DEFAULT AS IDENTITY,
    name text NOT NULL,
    created_at timestamp WITH time zone NOT NULL DEFAULT now(),
    updated_at timestamp WITH time zone,
    started_at timestamp WITH time zone,
    finished_at timestamp WITH time zone,
    min_value bigint DEFAULT 1 NOT NULL,
    max_value bigint NOT NULL,
    batch_size integer NOT NULL,
    status smallint DEFAULT 0 NOT NULL,
    job_signature_name text NOT NULL,
    table_name text NOT NULL,
    column_name text NOT NULL,
    CONSTRAINT pk_batched_background_migrations PRIMARY KEY (id),
    CONSTRAINT unique_batched_background_migrations_name UNIQUE (name)
);
```

- `id`: Unique identifier for the migration (auto-generated).
- `name`: A unique name that identifies the migration (ideally, all names should follow the format `<timestamp>_<migration_description>`).
- `created_at`: Timestamp when the migration was created.
- `updated_at`: Timestamp when the migration was last updated.
- `started_at`: Timestamp when the migration was last started.
- `finished_at`: Timestamp when the migration was successfully completed.
- `min_value`: Starting row `id` eligible for migration.
- `max_value`: Stopping row `id` eligible for migration. Used to exclude newly introduced records after a given point.
- `batch_size`: Number of rows that should be migrated per batch. A good starting point is usually 100,000.
- `status`: The current state of the migration (see table below).
- `job_signature_name`: The key that corresponds to a registry function that will be executed for each batch of the migration.
- `table_name`: The table the migration is run on. Must follow the format `<schema>.<table>`.
- `column_name`: The column used to determine the next batch.

Status values:

| status     | value | description                                                                                                                                                                                       |
| ---------- | ----- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `paused`   | 0     | No new jobs for the migration will be created/run, and no failed jobs will be retried. Already active jobs updated to this status will be allowed to either run to successful completion or fail. |
| `active`   | 1     | The migration is ready to be picked up as soon as a job worker is available.                                                                                                                      |
| `finished` | 2     | The migration is complete (all batched jobs have run successfully and the migration has reached its batching bounds).                                                                             |
| `failed`   | 3     | The migration is marked as `failed` when at least one of the migration jobs has exceeded the maximum retry `attempts`. Manual intervention is required at this stage.                             |
| `running`  | 4     | The migration is ongoing (at least one job associated with the migration is not completed).                                                                                                       |

#### Jobs

```sql
CREATE TABLE batched_background_migration_jobs (
    id bigint NOT NULL GENERATED BY DEFAULT AS IDENTITY,
    created_at timestamp WITH time zone NOT NULL DEFAULT now(),
    updated_at timestamp WITH time zone,
    started_at timestamp WITH time zone,
    finished_at timestamp WITH time zone,
    batched_background_migration_id bigint NOT NULL,
    min_value bigint NOT NULL,
    max_value bigint NOT NULL,
    status smallint DEFAULT 1 NOT NULL,
    failure_error_code smallint,
    attempts smallint DEFAULT 0 NOT NULL,
    CONSTRAINT pk_batched_background_migrations_job PRIMARY KEY (id),
    CONSTRAINT fk_b_b_m_jobs_batched_background_migration_id_b_b_migrations 
        FOREIGN KEY (batched_background_migration_id) 
        REFERENCES batched_background_migrations(id) 
        ON DELETE CASCADE
);

CREATE INDEX idx_bbm_jobs_migration_id_status ON batched_background_migration_jobs (batched_background_migration_id, status);
CREATE INDEX idx_bbm_jobs_status ON batched_background_migration_jobs (status);

```

- `batched_background_migration_id`: References the batched background migration the job is tied to.
- `created_at`: Timestamp when the migration job was created.
- `started_at`: Timestamp when the migration job was first started. Creation of a job corresponds to the first effective start of the job.
- `updated_at`: Timestamp when the migration job was last updated.
- `finished_at`: Timestamp when the migration job was successfully completed.
- `min_value`: The starting `id` for the batch job.
- `max_value`: The stopping `id` for the batch job.
- `attempts`: How many times the batch job was tried.
- `status`: The current state of the job:

| status     | value | description                   |
| ---------- | ----- | ----------------------------- |
| `active`   | 1     | The job is in progress.       |
| `finished` | 2     | The job has finished.         |
| `failed`   | 3     | The job has failed.           |

- `failure_error_code`: The last error code associated with a `failed` job state. This corresponds to error codes emitted by the registry when a job fails:

| error code              | value | description                                                     |
| ----------------------- | ----- | --------------------------------------------------------------- |
| `unknown`               | 0     | The job/migration failed with an unknown error code             |
| `invalid_bbm_table`     | 1     | Invalid migration table reference                               |
| `invalid_bbm_column`    | 2     | Invalid background migration column reference                   |
| `invalid_job_signature` | 3     | Invalid job signature reference                                 |
| `max_job_retry`         | 4     | A migration's job exceeded the maximum configured retry attempt |

## Batching strategies

The Registry supports two primary batching strategies for background migrations:

**ID/Serial Keyset Batching (default):** This strategy paginates using a monotonically increasing column, typically the `id`. It employs keyset semantics, where each job is defined by `min_value` and `max_value` bounds, allowing the work function to operate over a specified range of data.

**Null/Predicate Batching:** This approach targets rows that meet a specific condition, typically `WHERE <column> IS NULL`. It is particularly useful for backfilling tables that lack a numeric serial keyset pagination column. Instead of using numeric ranges, this strategy relies on predicates for selection. Jobs modify the predicate within the same transaction, reducing the number of records that need to satisfy the predicate in future jobs.

For Null/Predicate Batching, there are important considerations:

- **Concurrency and Idempotence:** The work must be idempotent and should modify the predicate (e.g., update the NULL column) within the same transaction to prevent reprocessing the same rows repeatedly.

- **Performance Optimization:** It is crucial to add an index to efficiently support the predicate, with a preference for a partial index. Without an index, the operation to check for remaining work can degrade into full table scans, especially in large tables, impacting performance significantly. The discussion [here](https://gitlab.com/gitlab-org/container-registry/-/issues/1248#note_1877479379) is a clear example of why this is needed.

## Creation

Batch Background Migrations (BBMs) are created by adding a new migration into the normal schema migrations. This process involves several steps:

1. Create a new schema migration file:
   - Add a new file in the migrations directory with a timestamp prefix, e.g., `20240815000000_add_new_bbm.go`.

1. Define the migration:
   - Implement both `Up()` and `Down()` methods.
   - In the `Up()` method, insert a record into the `batched_background_migrations` table.
      - Include all necessary fields: `name`, `job_signature_name`, `table_name`, `column_name`, `min_value`, `max_value`, `batch_size`, and `status`.
   - In the `Down()` method, remove the record from the `batched_background_migrations` table.

1. Implement the migration logic:
   - Create a new file `registry/datastore/migrations/background/{{name}}.go` to define your work function.
   - In this file, implement the work function that will be executed for each batch. The function should conform to the `WorkFunc` type defined in `registry/bbm/bbm.go`:

     ```go
     func YourMigrationFunction(ctx context.Context, db datastore.Handler, paginationTable, paginationColumn string, paginationAfter, paginationBefore int64, limit int) error {
         // Implement your migration logic here
     }
     ```

   - Register your function in the `AllWork` map within `bbm.go`:

     ```go
     // In bbm.go
     var AllWork = map[string]WorkFunc{
         "your_job_signature_name": YourMigrationFunction,
     }
     ```

   > **Important Notes:**
   >
   > 1. **Function Naming:** The `your_job_signature_name` key in the `AllWork` map must match the `job_signature_name` specified in the BBM record. This ensures proper function lookup and execution.
   >
   > 1. **Idempotency:** Work functions must be idempotent to guarantee safe retries. This means:
   >    - Executing the same function multiple times with identical input should produce the same result.
   >    - The function should not have unintended side effects on repeated executions.
   >    - Idempotency is critical for maintaining data integrity during retries and recovering from failures.

## Execution

### Asynchronously

Asynchronous BBMs run in the background during normal registry operation, minimizing impact on system performance.

Process:

1. Initialization: A BBM is created through a regular database migration, inserting a record into the batched_background_migrations table.
1. Worker Activation: Registry instances periodically start a worker to check for active BBMs.
1. Lock Acquisition: The worker attempts to acquire a distributed lock to ensure only one instance processes a migration at a time.
1. Migration Processing:
   1. If a lock is acquired, the worker fetches an active BBM.
   1. It creates a new job in the `batched_background_migration_jobs` table or picks up a failed job for retry.
   1. The worker executes the job using the function specified by `job_signature_name`.
   1. Upon completion, it updates the job status and releases the lock.
1. Completion: This process repeats periodically until all jobs for the BBM are completed or the maximum retry attempts are reached.
1. Status Update: The BBM status is updated to 'finished' or 'failed' based on the outcome.

```plantuml
actor "Registry Instance" as RI
participant "BBM Worker" as Worker
database "Database" as DB
participant "Lock Mechanism" as Lock

RI -> Worker: Start
activate Worker

loop periodically
    Worker -> Lock: Attempt to acquire lock
    activate Lock
    alt Lock acquired
        Lock --> Worker: Lock granted
        Worker -> DB: Fetch active BBM
        activate DB
        DB --> Worker: Return BBM details
        Worker -> DB: Create/Fetch job
        DB --> Worker: Job details
        Worker -> Worker: Execute job
        Worker -> DB: Update job status
        Worker -> DB: Update BBM status if complete
        deactivate DB
        Worker -> Lock: Release lock
    else Lock not acquired
        Lock --> Worker: Lock denied
    end
    deactivate Lock
end
deactivate Worker

```

#### Back-off Strategy

The asynchronous background migration worker uses exponential back-off to dynamically adjust sleep intervals between job cycles based on execution outcomes. This strategy ensures rapid job processing when work is available while minimizing resource consumption and coordinating multiple workers during quiet periods or system stress conditions.

##### Back-off Behavior

**Reset to minimum interval (1 minute):**

- Job found and executed successfully — likely more jobs exist
- Failed to obtain distributed lock — another worker may be processing jobs

**Exponential increase (up to 30 minutes maximum):**

- No jobs found — reduces database load during idle periods  
- Job execution failed — allows system recovery time
- High WAL pressure detected — eases database write pressure

##### Sleep Intervals and Jitter

The sleep interval follows an exponential progression with 33% randomization:

```plaintext
Base intervals: 1min → 2min → 4min → 8min → 16min → 30min (max)
With jitter:    ±33% random variation around each base interval
```

For example, a 4-minute base interval becomes 2.7–5.3 minutes randomly. This jitter prevents the "thundering herd" problem when multiple worker instances restart simultaneously, ensuring they don't all compete for jobs at the same time.

Additionally, each worker applies random startup jitter (0–60 seconds) when first starting to further distribute initial job checks across the worker fleet.

## Synchronously

Synchronous BBMs are executed manually via the registry CLI process, allowing registry administrators to directly manage migrations. Synchronous migration runs offer a higher level of urgency compared to asynchronous migrations, as they attempt to run migrations to completion without interruption. By using the CLI, administrators can initiate, monitor, and verify the completion of these migrations in real-time, providing immediate results and a higher level of control over the migration process. This approach is particularly useful for time-sensitive database updates or when immediate migration completion is required.

Process:

1. Admin initiates process via CLI command.
1. Migration Worker starts and unpauses migrations.
1. Migrations are run until all migrations complete or critical error occurs:
   - Begin transaction and acquire lock.
   - Process jobs in batches within transaction (up to a maximum).
   - Handle job execution, retries, and error reporting.
   - Commit transaction and release lock after transactional batch completion.
1. Process terminates with success or failure report to admin.

```plantuml
actor Administrator
participant "CLI Command" as CLI
participant "Migration Worker" as Worker
database "Database" as DB

Administrator -> CLI: Initiate synchronous migration
activate CLI

CLI -> Worker: Start migration process
activate Worker

Worker -> DB: Unpause migrations

  loop until all migrations processed or critical error
      Worker -> DB: Begin transaction and acquire lock
      activate DB
    
      loop until max jobs per transaction or no more jobs
          Worker -> DB: Find next eligible job
          DB --> Worker: Job details
        alt all jobs completed successfully
           Worker -> CLI: Report successful completion
           CLI -> Administrator: Display success message and terminate
          else pending job found
              loop retry attempts
                  Worker -> Worker: Execute job
                  alt job succeeds
                      Worker -> DB: Mark job as completed
                      break
                  else job fails
                      Worker -> Worker: Log error and retry
                  end
              end
            
              alt max retries exceeded
                  Worker -> CLI: Report critical error
                  CLI -> Administrator: Display error and terminate
                  break
              end
          else no job found
              Worker -> DB: Update migration status if needed
              break
          end
         end
      end
   end
end
    Worker -> DB: Commit transaction and release lock
    Worker -> Worker: Introduce delay before next transaction batch
end

deactivate Worker
deactivate CLI
```

## Retry and Recovery

Each Migration is run once and each job in a migration can be run up to a configurable number of attempts. The behavior differs between asynchronous and synchronous processes:

1. For asynchronous BBM runs:
   - Uses a default maximum job attempt value of 5.
   - All migration jobs are guaranteed to be run only once before any failed jobs can be retried.
   - After all jobs have been run at least once, the registry then proceeds to run each failed job up to the default maximum job attempt value.
   - If any of the failed job's retry attempts (from `attempts` in `batched_background_migration_jobs` table) exceeds the default maximum (of 5), the migration is marked as failed regardless of other successful jobs in the BBM.
   - The `attempts` field in the database is updated for each retry.

1. For synchronous BBM runs during regular migrations:
   - Uses the `--max-job-retry` flag value provided in the CLI, which can be set between 1 and 10 (default is 2).
   - The process exits and returns an error if a job exceeds the maximum attempts provided in the CLI.
   - The `attempts` field in the database is not updated during synchronous runs, preserving the database state.

A failed BBM is not automatically retried and will require manual intervention to restart the BBM or investigate the issue. Failed BBMs are rare but if/when they do happen, they require investigation. On `GitLab.com`, we raise an error on Sentry whenever a BBM is marked as failed.

Ultimately, a failed BBM does not degrade the registry when it happens as part of the asynchronous BBM. It is up to the registry developer to enforce that a BBM is completed (using the assurance mechanism explained in [Finalizing BBM](#finalizing-a-bbm)) before using functionality introduced by the BBM within the registry codebase.

_Note_: A failed BBMs can always be re-run by using the [`background-migrate run` sub-command](#cli)

## CLI

The CLI exposes the following functionality for managing batched background migrations:

- `background-migrate status`: Show the current status of all batched background migrations. This command displays a table with the name and status of each migration, allowing users to monitor migration progress and audit the system.

- `background-migrate pause`: Pause all running or active batched background migrations. This command can be used to temporarily halt the execution of background migrations.

- `background-migrate resume`: Resume all paused batched background migrations. This command can be used to restart the asynchronous execution of previously paused background migrations.

- `background-migrate run`: Run all unfinished batched background migrations. This command executes any pending or failed migrations.

These CLI commands provide administrators with the necessary tools to manage, monitor, and control the execution of batched background migrations in the registry.

## Release process

### Introducing a new BBM

It is important to always introduce a background migration well in advance of any feature that uses the functionality introduced by the migration. This ensures that customers have had sufficient time to and headroom for the BBM to run to completion.

### Finalizing a BBM

Finalizing a BBM is required to ensure that code or schema migrations that rely on the BBM do not accidentally run before the BBM is complete. When introducing a BBM or a regular migration that depends on an existing BBM, we must ensure the existing BBM is complete before proceeding with the introductory schema migration.

This is handled in two ways:

1. For schema migrations: Specify the name(s) of the dependent BBM(s) in the `RequiredBBMs` field of a migration. Now when a `migrate up` command is run it will verify that all specified BBMs are complete before applying the migration.

1. For code paths: Use the BBM datastore method `AreFinished` to assert that the background migration(s) the code change depends on have finished.

This approach ensures that schema migrations and code changes stop the registry from proceeding until the required/dependent BBMs are fully complete, maintaining data integrity and preventing potential issues.

```plantuml
actor "Administrator" as Admin
participant "Migrator" as Migrator
participant "BackgroundMigrationStore" as BBMStore
database "Database" as DB

Admin -> Migrator: Initiate migrate up
activate Migrator

Migrator -> Migrator: Get eligible migrations from source
Migrator -> DB: Get applied migration records in database

loop for each eligible migration
    Migrator -> Migrator: Check if migration is already applied
    alt migration not applied
        Migrator -> Migrator: Check for required BBMs
        alt BBMs required
            Migrator -> BBMStore: Check BBM completion status
            alt BBMs not complete
                Migrator --> Admin: Return error (BBM not complete)
                break
            end
        end
        Migrator -> DB: Apply migration
        Migrator -> Migrator: Increment applied count
    end
    alt max migrations reached
        break
    end
end
end
end

Migrator --> Admin: Return number of applied migrations

deactivate Migrator
```

### Required stops

A [required stop](https://docs.gitlab.com/ee/development/database/required_stops.html) is a perfect place to enforce a BBM dependency on a regular migration. [TBD](https://gitlab.com/gitlab-org/container-registry/-/issues/1346)

## Troubleshooting

### Background Migration Dependency Errors

When a new migration is introduced that depends on a background migration that has not been finalized, running the `migrate up` command will fail. This failure is typically accompanied by an error message indicating that a required background migration is not complete. In such cases, the registry administrator has two options to resolve the issue:

1. **Synchronous execution**: Use the [CLI](#cli) to run the pending background migrations synchronously, ensuring they complete before proceeding with the new migration.

1. **Version downgrade and asynchronous completion**: Downgrade the registry to a version prior to when the background migration was marked as required. This allows the asynchronous process to complete the background migration.

It's worth noting that fresh registry installations can execute and finalize their background migrations as part of the regular migration process using `migrate up`, avoiding these issues.

### Work Function Not Found Error

During rolling upgrades or version rollbacks, background migration jobs may temporarily log a work function not found error when some worker pods lack the required function code. This transient error triggers exponential backoff (starting from the job interval and increasing up to 30 minutes) until all worker pods are updated with the necessary work functions. Unlike other background migration validation errors, this will not permanently mark the migration as failed, allowing it to automatically resume once the deployment is complete.

To avoid this we need to ensure the registry version containing the migration work function is deployed before inserting the migration into the database. We can do this by only creating background migration records in the database after the corresponding container registry version (with the migration function) has been released and deployed.

## Debugging

When a background migration encounters issues or fails, the reason for the failure is typically logged in the registry's log stream. Additional details regarding the failure can also be extracted from the `background_migrations` and/or `background_migration_jobs` tables. These tables provide high-level information about the migration's progress, which can be useful for troubleshooting.

**Timing Information**: The timing columns in both the `background_migrations` and `background_migration_jobs` tables are invaluable for troubleshooting performance and diagnosing issues. Each table includes several timestamp fields—such as `created_at`, `started_at`, `finished_at`, and `updated_at` which can help you track how long the migration or individual jobs have been running. For more details on the meaning of each of these columns in the context of the respective tables, refer to the column definitions in the [migration section](#migrations).

**Job and Migration**: Both tables also include a `status` field that indicates the current state of the migration or job. Checking the `status` field helps you determine whether a migration is still ongoing, completed, or encountered a failure. If the migration is marked as `failed`, you'll need to investigate further using the other available fields to understand why it failed. For a full explanation of the possible status values, refer to the definition of the `status` column in the [migration section](#migrations).

**Failure Diagnostics:** One of the most important fields to check when debugging failed migrations is the `failure_error_code`, which is present in both the `background_migrations` and `background_migration_jobs` tables. This field provides a specific error code that explains the reason for the failure. By checking the `failure_error_code`, you can quickly pinpoint the root cause of a failure. For example, if the error code is `1`, this indicates that there is an issue with the table definition, whereas `4` would suggest that the job has retried too many times without success, requiring manual intervention or adjustment of retry settings. All possible error codes are detailed in the [migration section's](#migrations) definition of the `failure_error_code` column.

**Attempt and Batch Information**: The `attempts` field in the `background_migration_jobs` table tracks how many times a job has been retried. If a job is repeatedly failing and retrying, it may indicate an underlying issue with the data, the migration logic, or the system configuration. By examining the number of attempts, you can determine if the failure is due to repeated retries and decide whether to adjust the migration parameters, such as retry limits, batch size, or job logic.
Additionally, the `min_value` and `max_value` fields in both the `background_migrations` and `background_migration_jobs` tables specify the range of records being processed by the migration or each job. If a migration fails during a specific range of records, these values can help you identify the problematic data. If multiple jobs fail in the same record range, this could indicate a data issue or a problem with the specific batch that needs to be addressed.

By carefully reviewing the `status`, timing, `failure_error_code`, `attempts`, and batch range fields, you can gather crucial insights into why a migration or job has failed and make informed decisions on how to resolve the issue, whether that involves adjusting batch sizes, correcting table or column references, or addressing any underlying data issues.

## Performance Testing Guide

When introducing new background migrations, it’s essential to assess how they will perform on a production-scale database. This ensures that the migration process runs efficiently and does not introduce any unforeseen bottlenecks or performance issues. The following guide will take you through the process of testing your background migration on a database clone, gathering performance data, and preparing a detailed report.

Before running a background migration on a live production/staging database, it’s critical to test the migration in a controlled environment. To do this you will need to:

1. Procure a clone of the production registry Database Lab Instance (`gitlab-production-registry`) database in [postgres.ai](https://console.postgres.ai/gitlab/gitlab-production-registry/instances). Once Procured take note of your chosen `username` `password` and the SSH command to connect your local port to the database instance.
   - If you are following this process for the first time, you may need to request the necessary access permissions to clone the database and connect to it from your local setup. To obtain the correct access, follow the instructions in the [Database Lab Access documentation](https://docs.gitlab.com/ee/development/database/database_lab.html#access-the-console-with-psql). You'll need to create an access request similar to the example provided here: [Example Access Request](https://gitlab.com/gitlab-com/team-member-epics/access-requests/-/issues/32379).

1. Start up a local port forwarding connection to the cloned Postgres instance from your local. The specific command to run will have been issued to you in 1 (after cloning the database in postgres.ai) and should look something like: `ssh -NTML 6000:localhost:6000 lab-registry-01-db-db-lab.c.gitlab-db-lab.internal`.

1. Build the registry with the background migration(s) you want to test. You can run `make bin/registry` from the root of the container-registry repository branch that contains your change to build the binary.

1. Edit your `./config/filesystem.yaml` to be able to connect to the cloned database using the credentials obtained in 1, the port forwarded-to in 2, and disable unnecessary background processes like online GC:

   ``` yaml
   database:
     enabled: true
     host: localhost
     port: 6000 # selected port forwarded to postgres instance used in 2.
     user: "registry" # username of cloned instance obtained in 1.
     password: "registrypassword" # password of cloned instance obtained in 1.
     dbname: "gitlabhq_registry_dblab"
     sslmode: "disable"
     backgroundmigrations:
       enabled: true
       jobinterval: 10s # Set this to the job interval used on Gitlab.com
   gc:
       disabled: true  # Disable garbage collection for this test
   ```

1. The Background Migrations process is still in beta and not enabled by default. To use the feature you must also set the feature flag environment variable `REGISTRY_FF_BBM` to `true` in your development environment before starting the registry: 

   ```shell
   export REGISTRY_FF_BBM=true
   ```

1. Apply any necessary schema changes (e.g., new indexes, tables) `./bin/registry database migrate up ./config/filesystem.yml`.

1. Start the registry and confirm that background migration jobs are running `./bin/registry serve ./config/filesystem.yml`. You should be able to see log entries referencing the background migration runs.

1. Use [`psql`](https://www.postgresql.org/docs/current/app-psql.html) (or any database tool of your choice), to connect to the database and check that the table selected for migration has some processed records as expected.

1. Use [`pg_activity`](https://github.com/dalibo/pg_activity) (or any database tool of your choice) to monitor server activity and SQL queries are expected.

1. Background migrations may take hours or days to complete depending on the batch size, frequency of the job runs, size of the database and queries being executed. While we do not need to wait for the background migration to run to completion we should allow the migration to run for at least 1 hour. This allows some time to gather enough data to estimate how long the full migration would take. After an hour (or more), stop the migration and collect key metrics:
   - Total records processed in migrating table.
   - Total existing records in migrating table.
   - Number of jobs completed.
   - Records processed per job (i.e. `batch_size`)
   - Records migrated per hour.
   - Extrapolated total migration time if the migration was to run to completion on the migrating table.
   - Note any errors or potential issues with the migration.
1. Prepare and add a report (of the format below) as a comment on the MR introducing the changes:

```markdown
**Migration on {{Table-Name}} Table**

**Run Settings**
- **Batch size**: X
- **Job interval**: X seconds

- **Run time**: X hours, XX minutes
- **Jobs completed**: XXX
- **Records migrated per job**: XXX,XXX records
- **Total records migrated**: XX,XXX,XXX records
- **Migration rate**: XX,XXX,XXXX records/hour
- **Total records in table**: XXX,XXX,XXX records

**Extrapolated Migration Time**:
- Estimated time to migrate entire table: XX.X hours (~X days)

**Other Notes**:
 - Observed errors/issues ...
 - etc..
```

## Release Plan (Phases)

The release of the first iteration of background migrations is structured into three distinct phases:

### Phase 1 (Beta) - Release MVC to GitLab.com

Phase 1 focuses on introducing the minimum viable change (MVC) of the background migration system to GitLab.com. This phase will enable the ability to manage and run background migrations while the registry is actively serving traffic, as well as through the Registry CLI.

For this phase, we have selected a background migration targeting the smallest table in [this migration plan](https://gitlab.com/groups/gitlab-org/-/epics/13805#note_1899438887). Specifically, we will migrate the `manifests` table to populate a new `media_type_id_convert_to_bigint` column. More details on the migration plan can be found [here](https://gitlab.com/groups/gitlab-org/-/epics/13805#note_1899438887)

#### Rollout Plan

The rollout of Phase 1 will proceed as follows:

1. **Enable Background Migration Process (Staging and Production)**:

   - **Staging**: First, we will enable the background migration system on the staging environment without activating any actual background migrations. This allows us to test the system when no migrations are present.
   - **Production**: Once the staging environment is verified and no issues are encountered, we will enable the background migration process (without activating any actual background migrations) on GitLab.com (production).

1. **Add Required Schema Migrations to Staging and Production**: We will deploy the necessary schema changes to support the background migration, specifically adding the `media_type_id_convert_to_bigint` column to the `manifests` table.

1. **Deploy the Background Migration to Staging**:

   - The background migration targeting the `manifests` table will be deployed to the staging environment. The deployment will be closely monitored to ensure it runs smoothly and without issues.

1. **Deploy the Background Migration to Production**:

   - After successful monitoring in staging, the background migration will be deployed to GitLab.com (production). We will continue to monitor its progress and ensure the migration completes successfully.

### Phase 2 (Beta) - Supporting Background Migrations on non-ID Columns

In Phase 2, the release will continue to target GitLab.com and will build on the existing functionality by adding support for [ID-less column migrations](https://gitlab.com/gitlab-org/container-registry/-/issues/1248).

The primary goal for this phase is to enable background migrations on the `blobs` table, which does not have a dedicated integer `id` column for keyset pagination. To make the blobs table compatible with the current background migration's strategy of using keyset pagination, we first need to add and backfill the `blobs` table's `id` column. This will allow us to paginate over the rows effectively in future background migrations.

This phase will introduce a new strategy to handle migrations for non-ID tables.

#### Rollout Plan

1. **Implement Background Migration Strategy**:

   - Develop and implement the new migration strategy for non-ID tables.

1. **Add Required Schema Migrations** :

   - We will deploy the necessary schema changes to support the background migration, specifically adding the `id` column to the `blobs` table.

1. **Implement Background Migration on `blobs` table** :

   - We will add a background migration on the `blobs` table (using the new strategy) to backfill the table's `id` column.

1. **Deploy Background Migration to Staging**:

   - Deploy the background migration to the staging environment and monitor its progress until it completes successfully.

1. **Deploy Background Migration to Production**:

   - Once the background migration has completed successfully in staging, deploy it to GitLab.com (production) and monitor its progress until it finishes.

### Phase 3 - General Availability (GA) & Self-Managed Release (TBD)

Phase 3 will mark the transition to **General Availability (GA)** and will include the release for **self-managed instances**. The key focus for this phase is to enable background migrations in self-managed installs, expand the capabilities of background migrations, improve visibility, and provide additional management tools.

#### Current requirements for GA

1. **Support for Background Migrations in Required Stop Processes**:

   - Ensure that the background migration process is integrated with necessary required stop processes, allowing proper handling during upgrades.

1. **Admin Area View**:

   - Add an interface in the **Admin Area** to provide administrators with visibility into the status and progress of background migrations.

1. **API for Background Migration Management**:

   - Expose a set of API endpoints to allow users to **start**, **stop**, **pause**, and **view the status** of background migrations programmatically.

1. **Migration Estimates**:

   - Provide estimation data for each background migration, such as expected duration or completion percentage, to help administrators track progress and make informed decisions.

1. **ChatOps Integration**:

   - Integrate ChatOps to allow GitLab developers to manage background migrations directly from Slack. This will provide an easy way for teams to control and gain visibility on background migrations.

## Out of scope

These following optimizations are out of scope for the initial release:

- Concurrent migration processing: To reduce complexity, for the first iteration only one migration and one job can be run at a time.

- Sub batching: It is often beneficial to run a dedicated migration query in a job batch on one "sub" batch (a smaller division of your batch) at a time. Although this is very useful I think we can consider introducing this when the need arises, for the time being we can make our batch small enough to satisfy our own constraints.

- Dynamic optimization of batch sizes: Rails can optimize the batch size per job based on how long a prior job took.

- Down migrating background migrations.
