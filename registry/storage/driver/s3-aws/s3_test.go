package s3

import (
	"context"
	"crypto/ecdsa"
	"crypto/elliptic"
	"crypto/rand"
	"crypto/tls"
	"crypto/x509"
	"crypto/x509/pkix"
	"encoding/pem"
	"fmt"
	"math/big"
	"net"
	"net/http"
	"net/http/httptest"
	"net/http/httputil"
	"net/url"
	"os"
	"path"
	"slices"
	"strconv"
	"strings"
	"sync"
	"testing"
	"time"

	v2_aws "github.com/aws/aws-sdk-go-v2/aws"
	v2_s3 "github.com/aws/aws-sdk-go-v2/service/s3"
	"github.com/aws/aws-sdk-go/aws"
	"github.com/aws/aws-sdk-go/aws/awserr"
	"github.com/aws/aws-sdk-go/service/s3"
	"github.com/aws/smithy-go"
	"github.com/aws/smithy-go/ptr"
	"github.com/benbjohnson/clock"
	dlog "github.com/docker/distribution/log"
	"github.com/docker/distribution/registry/internal/testutil"
	rngtestutil "github.com/docker/distribution/testutil"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"github.com/stretchr/testify/suite"

	storagedriver "github.com/docker/distribution/registry/storage/driver"
	dtestutil "github.com/docker/distribution/registry/storage/driver/internal/testutil"
	"github.com/docker/distribution/registry/storage/driver/s3-aws/common"
	v1 "github.com/docker/distribution/registry/storage/driver/s3-aws/v1"
	v2 "github.com/docker/distribution/registry/storage/driver/s3-aws/v2"
	"github.com/docker/distribution/registry/storage/driver/testsuites"
)

var (
	// Driver version control
	driverVersion    string
	fromParametersFn func(map[string]any) (storagedriver.StorageDriver, error)
	newDriverFn      func(*common.DriverParameters) (storagedriver.StorageDriver, error)

	// Credentials
	accessKey    string
	secretKey    string
	sessionToken string

	// S3 configuration
	bucket         string
	region         string
	regionEndpoint string
	objectACL      string

	// Security settings
	encrypt    bool
	keyID      string
	secure     bool
	skipVerify bool
	v4Auth     bool
	pathStyle  bool

	// Performance settings
	maxRequestsPerSecond int64
	maxRetries           int64

	// Logging
	logLevel        string
	objectOwnership bool

	missing []string

	checksumDisabled  bool
	checksumAlgorithm string
)

type envConfig struct {
	env      string
	value    any
	required bool
}

func init() {
	fetchEnvVarsConfiguration()
}

func fetchEnvVarsConfiguration() {
	driverVersion = os.Getenv(common.EnvDriverVersion)
	switch driverVersion {
	case common.V2DriverName:
		fromParametersFn = v2.FromParameters
		newDriverFn = v2.New
	case common.V1DriverName, common.V1DriverNameAlt:
		// v1 is the default
		fallthrough
	default:
		// backwards compatibility - if no version is defined, default to v2
		fromParametersFn = v1.FromParameters
		newDriverFn = v1.New
	}

	vars := []envConfig{
		{common.EnvAccessKey, &accessKey, false},
		{common.EnvSecretKey, &secretKey, false},
		{common.EnvSessionToken, &sessionToken, false},

		{common.EnvBucket, &bucket, true},
		{common.EnvRegion, &region, true},
		{common.EnvRegionEndpoint, &regionEndpoint, false},
		{common.EnvEncrypt, &encrypt, true},

		{common.EnvObjectACL, &objectACL, false},
		{common.EnvKeyID, &keyID, false},
		{common.EnvSecure, &secure, false},
		{common.EnvSkipVerify, &skipVerify, false},
		{common.EnvV4Auth, &v4Auth, false},
		{common.EnvPathStyle, &pathStyle, false},

		{common.EnvMaxRequestsPerSecond, &maxRequestsPerSecond, false},
		{common.EnvMaxRetries, &maxRetries, false},

		{common.EnvLogLevel, &logLevel, false},
		{common.EnvObjectOwnership, &objectOwnership, false},

		{common.EnvChecksumDisabled, &checksumDisabled, false},
		{common.EnvChecksumAlgorithm, &checksumAlgorithm, false},
	}

	// Set defaults for boolean values
	secure = true
	v4Auth = true
	maxRequestsPerSecond = common.DefaultMaxRequestsPerSecond
	maxRetries = common.DefaultMaxRetries

	missing = make([]string, 0)
	for _, v := range vars {
		val := os.Getenv(v.env)
		if val == "" {
			if v.required {
				missing = append(missing, v.env)
			}
			continue
		}

		var err error
		switch vv := v.value.(type) {
		case *string:
			*vv = val
		case *bool:
			*vv, err = strconv.ParseBool(val)
		case *int64:
			*vv, err = strconv.ParseInt(val, 10, 64)
		}

		if err != nil {
			missing = append(
				missing,
				fmt.Sprintf("invalid value for %q: %s", v.env, val),
			)
		}
	}

	if regionEndpoint != "" {
		pathStyle = true // force pathstyle when endpoint is set
	}
}

func fetchDriverConfig(rootDirectory, storageClass string, logger dlog.Logger) (*common.DriverParameters, error) {
	rawParams := map[string]any{
		common.ParamAccessKey:                   accessKey,
		common.ParamSecretKey:                   secretKey,
		common.ParamBucket:                      bucket,
		common.ParamRegion:                      region,
		common.ParamRootDirectory:               rootDirectory,
		common.ParamStorageClass:                storageClass,
		common.ParamSecure:                      secure,
		common.ParamV4Auth:                      v4Auth,
		common.ParamEncrypt:                     encrypt,
		common.ParamKeyID:                       keyID,
		common.ParamSkipVerify:                  skipVerify,
		common.ParamPathStyle:                   pathStyle,
		common.ParamSessionToken:                sessionToken,
		common.ParamRegionEndpoint:              regionEndpoint,
		common.ParamMaxRequestsPerSecond:        maxRequestsPerSecond,
		common.ParamMaxRetries:                  maxRetries,
		common.ParamParallelWalk:                true,
		common.ParamObjectOwnership:             objectOwnership,
		common.ParamChunkSize:                   common.MinChunkSize,
		common.ParamMultipartCopyChunkSize:      common.DefaultMultipartCopyChunkSize,
		common.ParamMultipartCopyMaxConcurrency: common.DefaultMultipartCopyMaxConcurrency,
		common.ParamMultipartCopyThresholdSize:  common.DefaultMultipartCopyThresholdSize,
		common.ParamChecksumDisabled:            checksumDisabled,
	}

	if objectACL != "" {
		rawParams[common.ParamObjectACL] = objectACL
	}
	if logLevel != "" {
		switch driverVersion {
		case common.V2DriverName:
			rawParams[common.ParamLogLevel] = common.ParseLogLevelParamV2(logger, logLevel)
		default:
			rawParams[common.ParamLogLevel] = common.ParseLogLevelParamV1(logger, logLevel)
		}
	} else {
		switch driverVersion {
		case common.V2DriverName:
			rawParams[common.ParamLogLevel] = v2_aws.ClientLogMode(0)
		default:
			rawParams[common.ParamLogLevel] = aws.LogOff
		}
	}

	if checksumAlgorithm != "" {
		rawParams[common.ParamChecksumAlgorithm] = checksumAlgorithm
	}

	parsedParams, err := common.ParseParameters(driverVersion, rawParams)
	if err != nil {
		return nil, fmt.Errorf("parsing s3 parameters: %w", err)
	}
	return parsedParams, nil
}

func s3DriverConstructor(rootDirectory, storageClass string, logger dlog.Logger) (storagedriver.StorageDriver, error) {
	parsedParams, err := fetchDriverConfig(rootDirectory, storageClass, logger)
	if err != nil {
		return nil, fmt.Errorf("parsing s3 parameters: %w", err)
	}

	return newDriverFn(parsedParams)
}

func s3DriverConstructorT(t *testing.T, rootDirectory, storageClass string) storagedriver.StorageDriver {
	d, err := s3DriverConstructor(
		rootDirectory,
		storageClass,
		dlog.GetLogger(dlog.WithTestingTB(t)),
	)
	require.NoError(t, err)

	return d
}

func prefixedS3DriverConstructorT(t *testing.T) storagedriver.StorageDriver {
	rootDir := t.TempDir()
	d, err := s3DriverConstructor(rootDir, s3.StorageClassStandard, dlog.GetLogger(dlog.WithTestingTB(t)))
	require.NoError(t, err)

	return d
}

func skipCheck(envVarsRequired bool, supportedDriverVersions ...string) string {
	if envVarsRequired && len(missing) > 0 {
		return fmt.Sprintf(
			"Invalid value or missing environment values required to run S3 tests: %s",
			strings.Join(missing, ", "),
		)
	}
	driverVersion = os.Getenv(common.EnvDriverVersion)
	if len(supportedDriverVersions) > 0 && !slices.Contains(supportedDriverVersions, driverVersion) {
		return fmt.Sprintf("Test is not supported for driver %q, supported versions: %v", driverVersion, supportedDriverVersions)
	}
	return ""
}

func TestS3DriverSuite(t *testing.T) {
	if skipMsg := skipCheck(true); skipMsg != "" {
		t.Skip(skipMsg)
	}

	root := t.TempDir()

	ts := testsuites.NewDriverSuite(
		dlog.WithLogger(context.Background(), dlog.GetLogger(dlog.WithTestingTB(t))),
		func() (storagedriver.StorageDriver, error) {
			return s3DriverConstructor(
				root,
				s3.StorageClassStandard,
				dlog.GetLogger(dlog.WithTestingTB(t)),
			)
		},
		func() (storagedriver.StorageDriver, error) {
			return s3DriverConstructor(
				"",
				s3.StorageClassStandard,
				dlog.GetLogger(dlog.WithTestingTB(t)),
			)
		},
		nil,
	)
	suite.Run(t, ts)
}

func BenchmarkS3DriverSuite(b *testing.B) {
	if skipMsg := skipCheck(true); skipMsg != "" {
		b.Skip(skipMsg)
	}

	root := b.TempDir()

	ts := testsuites.NewDriverSuite(
		dlog.WithLogger(context.Background(), dlog.GetLogger(dlog.WithTestingTB(b))),
		func() (storagedriver.StorageDriver, error) {
			return s3DriverConstructor(
				root,
				s3.StorageClassStandard,
				dlog.GetLogger(dlog.WithTestingTB(b)),
			)
		},
		func() (storagedriver.StorageDriver, error) {
			return s3DriverConstructor(
				"",
				s3.StorageClassStandard,
				dlog.GetLogger(dlog.WithTestingTB(b)),
			)
		},
		nil,
	)

	ts.SetupSuiteWithB(b)
	b.Cleanup(func() { ts.TearDownSuiteWithB(b) })

	// NOTE(prozlach): This is a method of embedded function, we need to pass
	// the reference to "outer" struct directly
	benchmarks := ts.EnumerateBenchmarks()

	for _, benchmark := range benchmarks {
		b.Run(benchmark.Name, benchmark.Func)
	}
}

func TestS3DriverPathStyle(t *testing.T) {
	// Helper function to extract domain from S3 URL
	extractDomain := func(urlStr string) string {
		parsedURL, err := url.Parse(urlStr)
		require.NoError(t, err)
		return parsedURL.Host
	}

	// Helper function to check if URL uses path style
	isPathStyle := func(urlStr, bucket string) bool {
		parsedURL, err := url.Parse(urlStr)
		require.NoError(t, err)
		return strings.HasPrefix(parsedURL.Path, "/"+bucket)
	}

	// Base configuration that's common across all tests
	baseParams := map[string]any{
		"region": "us-west-2",
		"bucket": "test-bucket",
	}

	testCases := []struct {
		name           string
		paramOverrides map[string]any
		wantPathStyle  bool
		wantedEndpoint string
	}{
		{
			name: "path style disabled without endpoint",
			paramOverrides: map[string]any{
				"pathstyle": "false",
			},
			wantPathStyle:  false,
			wantedEndpoint: "test-bucket.s3.us-west-2.amazonaws.com",
		},
		{
			name: "path style enabled without endpoint",
			paramOverrides: map[string]any{
				"pathstyle": "true",
			},
			wantPathStyle:  true,
			wantedEndpoint: "s3.us-west-2.amazonaws.com",
		},
		{
			name: "path style disabled with custom endpoint",
			paramOverrides: map[string]any{
				"regionendpoint": "https://custom-endpoint:9000",
				"pathstyle":      "false",
			},
			wantPathStyle:  false,
			wantedEndpoint: "test-bucket.custom-endpoint:9000",
		},
		{
			name: "path style enabled with custom endpoint",
			paramOverrides: map[string]any{
				"regionendpoint": "https://custom-endpoint:9000",
				"pathstyle":      "true",
			},
			wantPathStyle:  true,
			wantedEndpoint: "custom-endpoint:9000",
		},
		{
			name: "default path style with custom endpoint",
			paramOverrides: map[string]any{
				"regionendpoint": "https://custom-endpoint:9000",
			},
			wantPathStyle:  true, // Path style should be forced when endpoint is set
			wantedEndpoint: "custom-endpoint:9000",
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(tt *testing.T) {
			// Merge base parameters with test-specific overrides
			params := make(map[string]any)
			for k, v := range baseParams {
				params[k] = v
			}
			for k, v := range tc.paramOverrides {
				params[k] = v
			}

			d, err := fromParametersFn(params)
			require.NoError(tt, err, "unable to create driver")

			// Generate a signed URL to verify the path style and endpoint behavior
			testPath := "/test/file.txt"
			urlStr, err := d.URLFor(
				dlog.WithLogger(context.Background(), dlog.GetLogger(dlog.WithTestingTB(t))),
				testPath, map[string]any{
					"method": "GET",
				},
			)
			require.NoError(tt, err, "unable to generate URL")

			// Verify the endpoint
			domain := extractDomain(urlStr)
			require.Equal(tt, tc.wantedEndpoint, domain, "unexpected endpoint")

			// Verify path style vs virtual hosted style
			bucket := params["bucket"].(string)
			actualPathStyle := isPathStyle(urlStr, bucket)
			require.Equal(tt, tc.wantPathStyle, actualPathStyle,
				"path style mismatch, URL: %s", urlStr)
		})
	}
}

func TestS3DriverEmptyRootList(t *testing.T) {
	if skipMsg := skipCheck(true); skipMsg != "" {
		t.Skip(skipMsg)
	}

	validRoot := t.TempDir()

	rootedDriver := s3DriverConstructorT(t, validRoot, s3.StorageClassStandard)
	emptyRootDriver := s3DriverConstructorT(t, "", s3.StorageClassStandard)
	slashRootDriver := s3DriverConstructorT(t, "/", s3.StorageClassStandard)

	filename := "/test"
	contents := []byte("contents")
	ctx := dlog.WithLogger(context.Background(), dlog.GetLogger(dlog.WithTestingTB(t)))
	err := rootedDriver.PutContent(ctx, filename, contents)
	require.NoError(t, err, "unexpected error creating content")
	defer rootedDriver.Delete(ctx, filename)

	keys, _ := emptyRootDriver.List(ctx, "/")
	for _, key := range keys {
		require.Truef(t, storagedriver.PathRegexp.MatchString(key), "unexpected string in path: %q != %q", key, storagedriver.PathRegexp)
	}

	keys, _ = slashRootDriver.List(ctx, "/")
	for _, key := range keys {
		require.Truef(t, storagedriver.PathRegexp.MatchString(key), "unexpected string in path: %q != %q", key, storagedriver.PathRegexp)
	}
}

func TestS3DriverStorageClass(t *testing.T) {
	if skipMsg := skipCheck(true); skipMsg != "" {
		t.Skip(skipMsg)
	}

	testCases := []struct {
		name         string
		storageClass string
		// expectedStorageClass is the expected value returned by S3 API
		// Amazon only populates this header for non-standard storage classes
		expectedStorageClass string
	}{
		{
			name:                 "Standard",
			storageClass:         "STANDARD",
			expectedStorageClass: "", // Amazon doesn't return a value for standard class
		},
		{
			name:                 "ReducedRedundancy",
			storageClass:         "REDUCED_REDUNDANCY",
			expectedStorageClass: "REDUCED_REDUNDANCY",
		},
		{
			name:                 "StandardIA",
			storageClass:         "STANDARD_IA",
			expectedStorageClass: "STANDARD_IA",
		},
		{
			name:                 "OnezoneIA",
			storageClass:         "ONEZONE_IA",
			expectedStorageClass: "ONEZONE_IA",
		},
		{
			name:                 "IntelligentTiering",
			storageClass:         "INTELLIGENT_TIERING",
			expectedStorageClass: "INTELLIGENT_TIERING",
		},
		{
			name:                 "Outposts",
			storageClass:         "OUTPOSTS",
			expectedStorageClass: "OUTPOSTS",
		},
		{
			name:                 "GlacierIR",
			storageClass:         "GLACIER_IR",
			expectedStorageClass: "GLACIER_IR",
		},
		{
			name:                 "ExpressOnezone",
			storageClass:         "EXPRESS_ONEZONE",
			expectedStorageClass: "EXPRESS_ONEZONE",
		},
		{
			name:                 "None",
			storageClass:         common.StorageClassNone,
			expectedStorageClass: "", // Same behavior as standard, no explicit value returned
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(tt *testing.T) {
			rootDir := tt.TempDir()

			driver := s3DriverConstructorT(tt, rootDir, tc.storageClass)

			// Skip storage class verification for StorageClassNone as it's just a config check
			if tc.storageClass == common.StorageClassNone {
				return
			}

			driverKeyer, ok := driver.(common.S3BucketKeyer)
			require.True(tt, ok, "driver should implement S3BucketKeyer interface")

			filename := "/test-" + strings.ToLower(tc.name)
			contents := []byte("contents")
			ctx := dlog.WithLogger(context.Background(), dlog.GetLogger(dlog.WithTestingTB(tt)))

			err := driver.PutContent(ctx, filename, contents)
			if err != nil {
				// Skip test if the storage class is not supported by the S3 service
				if strings.Contains(err.Error(), "InvalidStorageClass") {
					tt.Skipf("Storage class %q not supported by this S3 service", tc.storageClass)
					return
				}
				require.NoError(tt, err, "unexpected error creating content")
			}
			defer driver.Delete(ctx, filename)

			// NOTE(prozlach): Our storage driver does not expose API method that
			// allows fetching the storage class of the object, we need to create a
			// native S3 client to do that.
			parsedParams, err := fetchDriverConfig(
				rootDir,
				s3.StorageClassStandard,
				dlog.GetLogger(dlog.WithTestingTB(tt)),
			)
			require.NoError(tt, err)

			var storageClass string
			switch driverVersion {
			case common.V2DriverName:
				s3API, err := v2.NewS3API(parsedParams)
				require.NoError(tt, err)

				resp, err := s3API.GetObject(
					ctx,
					&v2_s3.GetObjectInput{
						Bucket: ptr.String(parsedParams.Bucket),
						Key:    ptr.String(driverKeyer.S3BucketKey(filename)),
					})
				require.NoError(tt, err, "unexpected error retrieving object")
				defer resp.Body.Close()
				storageClass = string(resp.StorageClass)
			default:
				s3API, err := v1.NewS3API(parsedParams)
				require.NoError(tt, err)

				resp, err := s3API.GetObjectWithContext(
					ctx,
					&s3.GetObjectInput{
						Bucket: ptr.String(parsedParams.Bucket),
						Key:    ptr.String(driverKeyer.S3BucketKey(filename)),
					})
				require.NoError(tt, err, "unexpected error retrieving object")
				defer resp.Body.Close()
				storageClass = ptr.ToString(resp.StorageClass)
			}

			if tc.expectedStorageClass == "" {
				require.Empty(
					tt, storageClass,
					"unexpected storage class for %s file: %v", tc.name, storageClass,
				)
			} else {
				require.Equalf(
					tt, tc.expectedStorageClass, storageClass,
					"unexpected storage class for %s file: %v", tc.name, storageClass,
				)
			}
		})
	}
}

func TestS3DriverOverThousandBlobs(t *testing.T) {
	if skipMsg := skipCheck(true); skipMsg != "" {
		t.Skip(skipMsg)
	}

	standardDriver := prefixedS3DriverConstructorT(t)

	ctx := dlog.WithLogger(context.Background(), dlog.GetLogger(dlog.WithTestingTB(t)))
	for i := 0; i < 1005; i++ {
		filename := "/thousandfiletest/file" + strconv.Itoa(i)
		contents := []byte("contents")
		err := standardDriver.PutContent(ctx, filename, contents)
		require.NoError(t, err, "unexpected error creating content")
	}

	// cant actually verify deletion because read-after-delete is inconsistent, but can ensure no errors
	err := standardDriver.Delete(ctx, "/thousandfiletest")
	require.NoError(t, err, "unexpected error deleting thousand files")
}

func TestS3DriverURLFor(t *testing.T) {
	if skipMsg := skipCheck(true); skipMsg != "" {
		t.Skip(skipMsg)
	}

	ctx := dlog.WithLogger(context.Background(), dlog.GetLogger(dlog.WithTestingTB(t)))
	d := prefixedS3DriverConstructorT(t)

	fp := "/foo"
	err := d.PutContent(ctx, fp, make([]byte, 0))
	require.NoError(t, err)

	// https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html
	param := "X-Amz-Expires"

	mock := clock.NewMock()
	mock.Set(time.Now())
	testutil.StubClock(t, &common.SystemClock, mock)

	t.Run("default expiry", func(tt *testing.T) {
		s, err := d.URLFor(ctx, fp, nil)
		require.NoError(tt, err)

		u, err := url.Parse(s)
		require.NoError(tt, err)
		require.Equal(tt, "1200", u.Query().Get(param))
	})

	t.Run("custom expiry", func(tt *testing.T) {
		dt := mock.Now().Add(1 * time.Hour)
		s, err := d.URLFor(ctx, fp, map[string]any{"expiry": dt})
		require.NoError(tt, err)

		u, err := url.Parse(s)
		require.NoError(tt, err)
		expected := dt.Sub(mock.Now()).Seconds()
		require.Equal(tt, fmt.Sprint(expected), u.Query().Get(param))
	})

	t.Run("use HTTP HEAD method", func(tt *testing.T) {
		s, err := d.URLFor(
			ctx,
			fp,
			map[string]any{
				"method": http.MethodHead,
			},
		)
		require.NoError(tt, err)

		client := &http.Client{}

		req, err := http.NewRequest(http.MethodHead, s, nil)
		require.NoError(tt, err)
		respHead, err := client.Do(req)
		require.NoError(tt, err)
		defer respHead.Body.Close()
		require.Equal(tt, http.StatusOK, respHead.StatusCode)

		req, err = http.NewRequest(http.MethodGet, s, nil)
		require.NoError(tt, err)
		respGet, err := client.Do(req)
		require.NoError(tt, err)
		defer respGet.Body.Close()
		require.Equal(tt, http.StatusForbidden, respGet.StatusCode)
	})

	t.Run("use HTTP GET method", func(tt *testing.T) {
		s, err := d.URLFor(
			ctx,
			fp,
			map[string]any{
				"method": http.MethodGet,
			},
		)
		require.NoError(tt, err)

		client := &http.Client{}

		req, err := http.NewRequest(http.MethodGet, s, nil)
		require.NoError(tt, err)
		respGet, err := client.Do(req)
		require.NoError(tt, err)
		defer respGet.Body.Close()
		require.Equal(tt, http.StatusOK, respGet.StatusCode)

		req, err = http.NewRequest(http.MethodHead, s, nil)
		require.NoError(tt, err)
		respHead, err := client.Do(req)
		require.NoError(tt, err)
		defer respHead.Body.Close()
		require.Equal(tt, http.StatusForbidden, respHead.StatusCode)
	})

	t.Run("use unsupported HTTP method", func(tt *testing.T) {
		_, err := d.URLFor(
			ctx,
			fp,
			map[string]any{
				"method": http.MethodPost,
			},
		)
		require.Error(tt, err)
	})
}

func TestS3DriverMoveWithMultipartCopy(t *testing.T) {
	if skipMsg := skipCheck(true); skipMsg != "" {
		t.Skip(skipMsg)
	}

	d := prefixedS3DriverConstructorT(t)

	ctx := dlog.WithLogger(context.Background(), dlog.GetLogger(dlog.WithTestingTB(t)))
	sourcePath := "/source"
	destPath := "/dest"

	defer d.Delete(ctx, sourcePath)
	defer d.Delete(ctx, destPath)

	// An object larger than d's MultipartCopyThresholdSize will cause d.Move()
	// to perform a multipart copy. We should avoid sizes that are a multiply
	// of common.DefaultMultipartCopyThresholdSize in order to maximize tests
	// coverage.
	contents := rngtestutil.RandomBlob(t, 2*common.DefaultMultipartCopyThresholdSize+128)

	err := d.PutContent(ctx, sourcePath, contents)
	require.NoError(t, err, "unexpected error creating content")

	err = d.Move(ctx, sourcePath, destPath)
	require.NoError(t, err, "unexpected error moving file")

	received, err := d.GetContent(ctx, destPath)
	require.NoError(t, err, "unexpected error getting content")
	require.Equal(t, contents, received, "content differs")

	_, err = d.GetContent(ctx, sourcePath)
	require.ErrorAs(t, err, new(storagedriver.PathNotFoundError))
}

// TestFlushObjectTwiceChunkSize tests a corner case where both pending and
// ready part buffers are full and `Close()`/`Commit()` calls are made. It is
// meant as a preventive measure, just in case we change the code later one and
// get the inequalities wrong.
func TestFlushObjectTwiceChunkSize(t *testing.T) {
	if skipMsg := skipCheck(true); skipMsg != "" {
		t.Skip(skipMsg)
	}

	rootDir := t.TempDir()
	parsedParams, err := fetchDriverConfig(
		rootDir,
		s3.StorageClassStandard,
		dlog.GetLogger(dlog.WithTestingTB(t)),
	)
	require.NoError(t, err)
	d, err := newDriverFn(parsedParams)
	require.NoError(t, err)

	ctx := dlog.WithLogger(context.Background(), dlog.GetLogger(dlog.WithTestingTB(t)))
	destPath := "/" + dtestutil.RandomFilename(64)
	defer dtestutil.EnsurePathDeleted(ctx, t, d, destPath)
	t.Logf("destination blob path used for testing: %s", destPath)
	destContents := rngtestutil.RandomBlob(t, 2*2*parsedParams.ChunkSize)

	writer, err := d.Writer(ctx, destPath, false)
	require.NoError(t, err)
	_, err = writer.Write(destContents[:2*parsedParams.ChunkSize])
	require.NoError(t, err)
	err = writer.Close()
	require.NoError(t, err, "writer.Close: unexpected error")

	writer, err = d.Writer(ctx, destPath, true)
	require.NoError(t, err)
	_, err = writer.Write(destContents[2*parsedParams.ChunkSize:])
	require.NoError(t, err)
	err = writer.Commit()
	require.NoError(t, err)
	err = writer.Close()
	require.NoError(t, err)

	received, err := d.GetContent(ctx, destPath)
	require.NoError(t, err, "unexpected error getting content")
	require.Equal(t, destContents, received, "content differs")
}

func TestS3DriverClientTransport(t *testing.T) {
	if skipMsg := skipCheck(true); skipMsg != "" {
		t.Skip(skipMsg)
	}

	rootDir := t.TempDir()
	driverConfig, err := fetchDriverConfig(
		rootDir,
		s3.StorageClassStandard,
		dlog.GetLogger(dlog.WithTestingTB(t)),
	)
	require.NoError(t, err)

	var hostport string
	var host string
	var scheme string
	if driverConfig.RegionEndpoint == "" {
		// Construct the AWS endpoint based on region
		hostport = fmt.Sprintf("s3.%s.amazonaws.com", driverConfig.Region)
		host = hostport
		scheme = "https"
	} else {
		parsedURL, err := url.Parse(driverConfig.RegionEndpoint)
		require.NoError(t, err)
		hostport = parsedURL.Host
		host, _, err = net.SplitHostPort(parsedURL.Host)
		scheme = parsedURL.Scheme
		require.NoError(t, err)
	}

	// Create a proxy that forwards to real S3
	proxy := &httputil.ReverseProxy{
		Director: func(req *http.Request) {
			req.URL.Scheme = scheme
			req.URL.Host = hostport
			req.Host = host
		},
	}

	// Create a proxy server with self-signed certificate
	serverCert, err := generateSelfSignedCert([]string{"127.0.0.1"})
	require.NoError(t, err, "failed to generate test certificate")

	server := httptest.NewUnstartedServer(proxy)
	server.TLS = &tls.Config{Certificates: []tls.Certificate{serverCert}}
	server.StartTLS()
	defer server.Close()

	testCases := []struct {
		name       string
		skipVerify bool
		shouldFail bool
	}{
		{
			name:       "TLS verification enabled",
			skipVerify: false,
			shouldFail: true, // Should fail with self-signed cert when verification is enabled
		},
		{
			name:       "TLS verification disabled",
			skipVerify: true,
			shouldFail: false, // Should succeed with self-signed cert when verification is disabled
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(tt *testing.T) {
			parsedParams, err := fetchDriverConfig(
				rootDir,
				s3.StorageClassStandard,
				dlog.GetLogger(dlog.WithTestingTB(tt)),
			)
			require.NoError(tt, err)

			parsedParams.SkipVerify = tc.skipVerify
			parsedParams.RegionEndpoint = server.URL
			parsedParams.MaxRetries = 1
			parsedParams.PathStyle = true

			driver, err := newDriverFn(parsedParams)
			require.NoError(tt, err)

			// Use List operation to trigger an HTTPS request
			ctx := dlog.WithLogger(context.Background(), dlog.GetLogger(dlog.WithTestingTB(tt)))
			_, err = driver.List(ctx, "/")

			if tc.shouldFail {
				require.ErrorContainsf(
					tt,
					err, "x509: certificate signed by unknown authority",
					"expected certificate verification error, got: %v", err,
				)
			} else {
				require.Error(tt, err)
				switch driverVersion {
				case common.V2DriverName:
					var apiErr smithy.APIError
					require.ErrorAsf(tt, err, &apiErr,
						"expected AWS API error, got: %v", err)
					require.Equal(tt, "SignatureDoesNotMatch", apiErr.ErrorCode())
					require.Contains(tt, apiErr.ErrorMessage(),
						"The request signature we calculated does not match the signature you provided",
					)
				default:
					var awsErr awserr.Error
					require.ErrorAsf(tt, err, &awsErr,
						"expected AWS API error, got: %v", err)
					require.Equal(tt, "SignatureDoesNotMatch", awsErr.Code())
					require.Contains(tt, awsErr.Message(),
						"The request signature we calculated does not match the signature you provided",
					)
				}
			}
		})
	}
}

// generateSelfSignedCert creates a self-signed certificate for testing
// addresses can contain both hostnames and IP addresses
func generateSelfSignedCert(addresses []string) (tls.Certificate, error) {
	priv, err := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)
	if err != nil {
		return tls.Certificate{}, err
	}

	// Process addresses into DNS and IP SANs
	var dnsNames []string
	var ipAddresses []net.IP

	for _, addr := range addresses {
		if ip := net.ParseIP(addr); ip != nil {
			ipAddresses = append(ipAddresses, ip)
		} else {
			dnsNames = append(dnsNames, addr)
		}
	}

	template := x509.Certificate{
		SerialNumber: big.NewInt(1),
		Subject: pkix.Name{
			Organization: []string{"Test Corp"},
		},
		NotBefore: time.Now(),
		NotAfter:  time.Now().Add(time.Hour),

		KeyUsage:              x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature,
		ExtKeyUsage:           []x509.ExtKeyUsage{x509.ExtKeyUsageServerAuth},
		BasicConstraintsValid: true,

		// Add the processed SANs
		DNSNames:    dnsNames,
		IPAddresses: ipAddresses,
	}

	derBytes, err := x509.CreateCertificate(rand.Reader, &template, &template, &priv.PublicKey, priv)
	if err != nil {
		return tls.Certificate{}, err
	}

	privDER, err := x509.MarshalPKCS8PrivateKey(priv)
	if err != nil {
		return tls.Certificate{}, err
	}

	return tls.X509KeyPair(
		pem.EncodeToMemory(&pem.Block{Type: "CERTIFICATE", Bytes: derBytes}),
		pem.EncodeToMemory(&pem.Block{Type: "PRIVATE KEY", Bytes: privDER}),
	)
}

// TestWalkEmptyDir tests that the Walk and WalkParallel functions
// properly handle the "empty" directories - i.e. objects with zero size that
// are meant as placeholders.
func TestWalkEmptyDir(t *testing.T) {
	if skipMsg := skipCheck(true, common.V2DriverName); skipMsg != "" {
		t.Skip(skipMsg)
	}

	rootDirectory := t.TempDir()
	parsedParams, err := fetchDriverConfig(
		rootDirectory,
		s3.StorageClassStandard,
		dlog.GetLogger(dlog.WithTestingTB(t)),
	)
	require.NoError(t, err)
	driver, err := newDriverFn(parsedParams)
	require.NoError(t, err)

	ctx := dlog.WithLogger(context.Background(), dlog.GetLogger(dlog.WithTestingTB(t)))

	commonDir := "/" + dtestutil.RandomFilenameRange(8, 8)
	defer dtestutil.EnsurePathDeleted(ctx, t, driver, commonDir)

	t.Logf("root dir used for testing: %s", rootDirectory)
	destContents := rngtestutil.RandomBlob(t, 32)

	// Create directories with a structure like:
	// rootDirectory/commonDir/
	//   ├── dir1/
	//   │    ├── file1-1
	//   │    └── file1-2
	//   ├── dir2/  (this one will be empty)
	//   └── dir3/
	//        ├── file3-1
	//        └── file3-2

	dir1 := "/dir1"
	dir2 := "/dir2"
	dir3 := "/dir3"

	// Create map of all files to create with full paths
	fileStructure := map[string][]string{
		dir1: {
			path.Join(commonDir, dir1, "file1-1"),
			path.Join(commonDir, dir1, "file1-2"),
		},
		dir3: {
			path.Join(commonDir, dir3, "file3-1"),
			path.Join(commonDir, dir3, "file3-2"),
		},
	}

	// Create all files in all directories
	for _, files := range fileStructure {
		for _, filePath := range files {
			err := driver.PutContent(ctx, filePath, destContents)
			require.NoError(t, err)
		}
	}
	// we use the s3 sdk directly because the driver doesn't allow creation of
	// empty directories due to trailing slash
	s3API, err := v2.NewS3API(parsedParams)
	require.NoError(t, err)

	filePath := strings.TrimLeft(path.Join(rootDirectory, commonDir, dir2)+"/", "/")
	_, err = s3API.PutObject(
		ctx,
		&v2_s3.PutObjectInput{
			Bucket: ptr.String(parsedParams.Bucket),
			Key:    ptr.String(filePath),
		},
	)
	require.NoError(t, err)

	expectedPaths := []string{
		commonDir,
		path.Join(commonDir, dir1),
		path.Join(commonDir, dir2),
		path.Join(commonDir, dir3),
		fileStructure[dir1][0],
		fileStructure[dir1][1],
		fileStructure[dir3][0],
		fileStructure[dir3][1],
	}

	// Helper function to create a walk function that skips dir2
	createWalkFunc := func(pathCollector *sync.Map) storagedriver.WalkFn {
		return func(fInfo storagedriver.FileInfo) error {
			// attempt to split filepath into dir and filename, just like purgeuploads would.
			filePath := fInfo.Path()
			_, file := path.Split(filePath)
			if len(file) == 0 {
				return fmt.Errorf("File part of fileInfo.Path()==%q had zero length", filePath)
			}

			// Record that this path was visited
			pathCollector.Store(filePath, struct{}{})
			return nil
		}
	}

	// Verify all expected paths were visited and unexpected were not
	verifyPaths := func(ttt *testing.T, visitedPaths *sync.Map) {
		// Check expected paths were visited
		for _, expectedPath := range expectedPaths {
			_, found := visitedPaths.Load(expectedPath)
			assert.Truef(ttt, found, "Path %s should have been visited", expectedPath)
		}

		visitedPathsKeys := make([]string, 0, len(expectedPaths))
		visitedPaths.Range(func(key, _ any) bool {
			visitedPathsKeys = append(visitedPathsKeys, key.(string))
			return true
		})
		assert.ElementsMatch(ttt, expectedPaths, visitedPathsKeys)
	}

	t.Run("PlainWalk", func(tt *testing.T) {
		var visitedPaths sync.Map
		err := driver.Walk(ctx, "/", createWalkFunc(&visitedPaths))
		require.NoError(tt, err)
		verifyPaths(tt, &visitedPaths)
	})

	t.Run("ParallelWalk", func(tt *testing.T) {
		var visitedPaths sync.Map
		err := driver.WalkParallel(ctx, "/", createWalkFunc(&visitedPaths))
		require.NoError(tt, err)
		verifyPaths(tt, &visitedPaths)
	})
}
